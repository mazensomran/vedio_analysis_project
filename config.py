import os
import torch
from pathlib import Path
from typing import List, Dict, Any

# ุงููุณุงุฑุงุช ุงูุฃุณุงุณูุฉ
BASE_DIR = Path(__file__).resolve().parent

WORKING_DIR = Path("/kaggle/working/") # ุชุนุฑูู ูุฌูุฏ ุงูุนูู ุงูุฌุฏูุฏ
UPLOAD_DIR = BASE_DIR / "uploads"
OUTPUTS_DIR = BASE_DIR / "outputs"
MODELS_DIR = BASE_DIR / "models" # ูููู ุฃู ูููู ูุฐุง ุฏุงุฎู WORKING_DIR ุฃู ูุจูู ูู BASE_DIR ุฅุฐุง ูุงูุช ุงูููุงุฐุฌ ูุญููุฉ ูุณุจููุง
DATABASE_DIR = BASE_DIR / "database"
LOGS_DIR = BASE_DIR / "logs"

# ุฅูุดุงุก ุงููุฌูุฏุงุช ุฅุฐุง ูู ุชูู ููุฌูุฏุฉ
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUTS_DIR.mkdir(exist_ok=True)
MODELS_DIR.mkdir(exist_ok=True)
DATABASE_DIR.mkdir(exist_ok=True)
LOGS_DIR.mkdir(exist_ok=True)

# ุงูุชุญูู ูู ุชููุฑ GPU
GPU_AVAILABLE = torch.cuda.is_available()
GPU_COUNT = torch.cuda.device_count() if GPU_AVAILABLE else 0
GPU_NAME = torch.cuda.get_device_name(0) if GPU_AVAILABLE else "None"

print(f"๐ฏ ุญุงูุฉ GPU: {'ูุชุงุญ' if GPU_AVAILABLE else 'ุบูุฑ ูุชุงุญ'}")
if GPU_AVAILABLE:
    print(f"๐ฏ ุนุฏุฏ ุฃุฌูุฒุฉ GPU: {GPU_COUNT}")
    print(f"๐ฏ ุงุณู GPU: {GPU_NAME}")

# ุฅุนุฏุงุฏุงุช ุงูุชุทุจูู
APP_CONFIG = {
    "host": "127.0.0.1",
    "port": 8000,
    "debug": True,
    "max_file_size": 100 * 1024 * 1024,  # 100MB
    "allowed_extensions": [".mp4", ".avi", ".mov", ".mkv", ".webm"],
    "max_video_length": 1800,  # 30 ุฏูููุฉ ูุญุฏ ุฃูุตู ููููุฏูู
    "max_concurrent_processes": 2,  # ุงูุญุฏ ุงูุฃูุตู ููุนูููุงุช ุงููุชุฒุงููุฉ
    "temp_file_cleanup_hours": 24,  # ุชูุธูู ุงููููุงุช ุงููุคูุชุฉ ุจุนุฏ 24 ุณุงุนุฉ
}

# ุฅุนุฏุงุฏุงุช ุงููุนุงูุฌุฉ
PROCESSING_CONFIG = {
    # ุฅุนุฏุงุฏุงุช ุนุงูุฉ
    "target_width": 640,
    "target_height": 360,
    "target_fps": 15,
    "enable_fast_processing": True,
    "max_workers": 2 if GPU_AVAILABLE else 1,
    "frame_sampling_interval": 2,  # ุฃุฎุฐ ุนููุฉ ูู 10 ุฅุทุงุฑุงุช
    "batch_size": 4 if GPU_AVAILABLE else 2,  # ุญุฌู ุงูุฏูุนุฉ ูููุนุงูุฌุฉ

    # ุฅุนุฏุงุฏุงุช ูุดู ุงููุฌูู
    "face_detection_threshold": 0.3,
    "min_face_size": 20,  # ุงูุญุฏ ุงูุฃุฏูู ูุญุฌู ุงููุฌู (ุจูุณู)
    "max_face_size": 300,  # ุงูุญุฏ ุงูุฃูุตู ูุญุฌู ุงููุฌู (ุจูุณู)
    "face_aspect_ratio_min": 0.7,  # ูุณุจุฉ ุงูุนุฑุถ ุฅูู ุงูุงุฑุชูุงุน ุงูุฏููุง ูููุฌู
    "face_aspect_ratio_max": 1.4,  # ูุณุจุฉ ุงูุนุฑุถ ุฅูู ุงูุงุฑุชูุงุน ุงููุตูู ูููุฌู
    "target_face_width": 128,  # ุงูุนุฑุถ ุงููุณุชูุฏู ูููุฌู ุงููุณุชุฎุฑุฌ
    "target_face_height": 128, # ุงูุงุฑุชูุงุน ุงููุณุชูุฏู ูููุฌู ุงููุณุชุฎุฑุฌ
    "face_padding_ratio": 0.2, # ูุณุจุฉ ุงููุงูุด ุญูู ุงููุฌู ูุจู ุงููุต
    "enable_face_enhancement": False,  # ุชูููู ุชุญุณูู ุฏูุฉ ุงููุฌูู
    "min_face_size_for_enhancement": 50,  # ุงูุญุฏ ุงูุฃุฏูู ูุญุฌู ุงููุฌู ููุชุญุณูู

    # ุฅุนุฏุงุฏุงุช ูุดู ุงูุฃุดุฎุงุต
    "person_detection_threshold": 0.5,
    "min_person_size": 50,  # ุงูุญุฏ ุงูุฃุฏูู ูุญุฌู ุงูุดุฎุต (ุจูุณู)

    # ุฅุนุฏุงุฏุงุช ูุดู ุงููุต
    "text_detection_threshold": 0.5,
    "text_detection_enabled": True,
    "text_recognition_enabled": True,
    "min_text_confidence": 0.3,  # ุงูุญุฏ ุงูุฃุฏูู ูุซูุฉ ุงูุชุนุฑู ุนูู ุงููุต

    # ุฅุนุฏุงุฏุงุช ุงูุชุชุจุน
    "tracking_threshold": 0.5,
    "max_tracking_distance": 100,  # ุงููุณุงูุฉ ุงููุตูู ููุชุชุจุน ุจูู ุงูุฅุทุงุฑุงุช (ุจูุณู)
    "min_track_length": 5,  # ุงูุญุฏ ุงูุฃุฏูู ูุทูู ุงููุณุงุฑ ูุงุนุชุจุงุฑู ุตุงูุญุงู

    # ุฅุนุฏุงุฏุงุช ุงูุชุนุฑู ุนูู ุงููุดุงุท
    "activity_recognition_interval": 20,  # ุชุญููู ุงููุดุงุท ูู 30 ุฅุทุงุฑ
    "activity_history_size": 100,  # ุนุฏุฏ ุงูุชุญูููุงุช ุงูุณุงุจูุฉ ูุชุฎุฒูููุง

    # ุฅุนุฏุงุฏุงุช ุฅุฏุงุฑุฉ ุงูุฃุฎุทุงุก
    "max_404_retries": 20,  # ุงูุญุฏ ุงูุฃูุตู ููุญุงููุงุช 404 ูุจู ุงูุฅููุงู
    "max_processing_time": 3600,  # ุงูุญุฏ ุงูุฃูุตู ูุฒูู ุงููุนุงูุฌุฉ (ุซุงููุฉ)
    "retry_delay_seconds": 2,  # ููุช ุงูุงูุชุธุงุฑ ุจูู ุงููุญุงููุงุช ุงููุงุดูุฉ

    # ุฅุนุฏุงุฏุงุช ุงูุฐุงูุฑุฉ ูุงูุฃุฏุงุก
    "gpu_enabled": GPU_AVAILABLE,
    "gpu_memory_limit": 0.8 if GPU_AVAILABLE else 0,  # ุงุณุชุฎุฏุงู 80% ูู ุฐุงูุฑุฉ GPU
    "cpu_usage_limit": 0.7,  # ุงูุญุฏ ุงูุฃูุตู ูุงุณุชุฎุฏุงู CPU
    "memory_cleanup_interval": 50,  # ุชูุธูู ุงูุฐุงูุฑุฉ ูู 50 ุฅุทุงุฑ

    # ุฅุนุฏุงุฏุงุช ุงูุฌูุฏุฉ
    "video_quality": 23,  # ุฌูุฏุฉ ุงูููุฏูู ุงููุญูู (ูููุง ูู ุงูุฑูู ุฒุงุฏุช ุงูุฌูุฏุฉ)
    "image_quality": 85,  # ุฌูุฏุฉ ุงูุตูุฑ ุงููุญููุธุฉ
}

# ุฅุนุฏุงุฏุงุช ุงูููุงุฐุฌ
MODEL_CONFIG = {
    # ููุงุฐุฌ ูุดู ุงููุฌูู
    "face_detection_model": "yolov8m-face.pt",
    "scrfd_model_path": "sscrfd.onnx",
    "available_face_models": [
        "yolov8n-face.pt",
        "yolov8s-face.pt",
        "yolov8m-face.pt",
        "yolov8l-face.pt"
    ],

    # ููุงุฐุฌ ูุดู ุงูุฃุดุฎุงุต
    "person_detection_model": "yolov8s.pt",
    "available_person_models": [
        "yolov8n.pt",
        "yolov8s.pt",
        "yolov8m.pt",
        "yolov8l.pt",
        "yolov8x.pt"
    ],

    # ููุงุฐุฌ ุงูุชุนุฑู ุนูู ุงููุต
    "text_detection_model": "easyocr",
    "text_recognition_model": "easyocr",
    "easyocr_languages": ["ar", "en"],

    # ููุงุฐุฌ ุงูุชุนุฑู ุนูู ุงูููุงู
    "speech_recognition_model": "base",
    "available_whisper_models": [
        "tiny", "tiny.en",
        "base", "base.en",
        "small", "small.en",
        "medium", "medium.en",
        "large", "large-v1", "large-v2", "large-v3"
    ],

    # ููุงุฐุฌ ุงูุชุนุฑู ุนูู ุงููุดูุฏ ูุงููุดุงุท
    "scene_recognition_model": "Salesforce/blip-image-captioning-base",
    "activity_recognition_model": "Salesforce/blip-image-captioning-base",
    "available_scene_models": [
        "Salesforce/blip-image-captioning-base",
        "google/vit-base-patch16-224",
        "facebook/convnext-tiny-224"
    ],

    # ููุงุฐุฌ ุงูุชุชุจุน
    "tracking_model": "bytetrack",
    "available_tracking_models": ["bytetrack", "deepsort", "sort"],

    "face_enhancement_model": "EDSR_x2.pt",

    # ุฅุนุฏุงุฏุงุช ุงูุฌูุงุฒ
    "device": "cuda" if GPU_AVAILABLE else "cpu",
    "precision": "fp32", # <--- CHANGE THIS LINE FROM "fp16" to "fp32"
    "optimize_for_inference": True,

    # ุฅุนุฏุงุฏุงุช ุงูุชูุฒูู ูุงูุชุฎุฒูู
    "model_download_timeout": 300,  # 5 ุฏูุงุฆู
    "model_retry_attempts": 3,
    "model_cache_size": 1024 * 1024 * 1024,  # 1GB

# ููุงุฐุฌ ุงูุชุนุฑู ุนูู ุงููุดุงุท (Video Swin Transformer)
    "video_activity_model": "microsoft/video-swin-tiny-patch4-window7-224", # ูููุฐุฌ ุตุบูุฑ ูุณุฑูุน ููุจุฏุก
    "available_video_activity_models": [
        "microsoft/video-swin-tiny-patch4-window7-224",
        "microsoft/video-swin-base-patch4-window7-224"]
}

# ุฅุนุฏุงุฏุงุช EasyOCR
EASYOCR_CONFIG = {
    "gpu_enabled": GPU_AVAILABLE,
    "model_storage_directory": str(MODELS_DIR / "easyocr"),
    "download_enabled": True,
    "recog_network": "standard",
    "detector": True,  # โ ุงุณุชุฎุฏุงู detector ุจุฏูุงู ูู detector_enabled
    "recognizer": True, # โ ุงุณุชุฎุฏุงู recognizer ุจุฏูุงู ูู recognizer_enabled
    "batch_size": 10,
    "model_precision": "fp16", # if GPU_AVAILABLE else "fp32",  # โ ุงุณุชุฎุฏุงู fp32 ุจุฏูุงู ูู fp16
    "detector_threshold": 0.3,
    "recognizer_threshold": 0.3,
    "text_min_size": 10,
    "text_max_size": 500,
    "paragraph": False,
    "detail": 1,
}

# ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช
DATABASE_CONFIG = {
    "db_path": DATABASE_DIR / "video_analysis.db",
    "backup_path": DATABASE_DIR / "backups",
    "max_backups": 10,
    "backup_interval_hours": 24,
    "tables": {
        "processes": "processes",
        "faces": "faces",
        "texts": "texts",
        "transcriptions": "transcriptions",
        "tracking": "tracking",
        "scenes": "scenes",
        "activities": "activities",
        "errors": "errors"
    },
    "connection_timeout": 30,
    "journal_mode": "WAL",
    "cache_size": -2000,  # 2MB
}

# ุฅุนุฏุงุฏุงุช ุงูุชุณุฌูู (Logging)
LOGGING_CONFIG = {
    "log_level": "INFO",
    "log_file": LOGS_DIR / "video_analysis.log",
    "max_log_size": 10 * 1024 * 1024,  # 10MB
    "backup_count": 5,
    "log_format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "date_format": "%Y-%m-%d %H:%M:%S",
}

# ุฅุนุฏุงุฏุงุช ุงูุฃูุงู
SECURITY_CONFIG = {
    "cors_origins": ["*"],
    "rate_limiting_enabled": True,
    "max_requests_per_minute": 60,
    "api_key_required": False,
    "allowed_file_types": ["video/mp4", "video/avi", "video/quicktime", "video/x-msvideo"],
    "max_filename_length": 255,
    "sanitize_filenames": True,
}

# ุฅุนุฏุงุฏุงุช ุงูุฃุฏุงุก ูุงูุชุญุณูู
PERFORMANCE_CONFIG = {
    "thread_pool_size": 4,
    "io_timeout_seconds": 30,
    "max_retry_attempts": 3,
    "cache_enabled": True,
    "cache_size": 100,  # ุนุฏุฏ ุงูุนูุงุตุฑ ุงููุฎุฒูุฉ
    "cache_ttl_seconds": 300,  # 5 ุฏูุงุฆู
    "compression_enabled": True,
    "preload_models": False,  # ุชุญููู ุงูููุงุฐุฌ ูุณุจูุงู ุนูุฏ ุงูุชุดุบูู
}

# ุฅุนุฏุงุฏุงุช ูุนุงูุฌุฉ ุงูุตูุช
AUDIO_CONFIG = {
    "sample_rate": 16000,
    "channels": 1,
    "audio_format": "mp3",
    "audio_bitrate": "64k",
    "silence_threshold": 0.01,
    "min_audio_length": 1.0,  # ุซุงููุฉ
    "max_audio_length": 300.0,  # ุซุงููุฉ
}

# ุฅุนุฏุงุฏุงุช ูุนุงูุฌุฉ ุงูููุฏูู
VIDEO_CONFIG = {
    "codec": "libx264",
    "preset": "medium",
    "crf": 23,
    "pix_fmt": "yuv420p",
    "keyframe_interval": 30,
    "buffer_size": 10*1024 * 1024,  # 1MB
    "threads": 2,
}

# ุฅุนุฏุงุฏุงุช ุงูุชุฑุฌูุฉ ูุงููุบุงุช
LANGUAGE_CONFIG = {
    "supported_languages": ["ar", "en"],
    "default_language": "ar",
    "auto_detect_language": True,
    "translation_enabled": False,
    "language_detection_confidence": 0.7,
}


# ุฅูุดุงุก ุงููุฌูุฏุงุช ุงูุฅุถุงููุฉ
def setup_directories():
    """ุฅุนุฏุงุฏ ุฌููุน ุงููุฌูุฏุงุช ุงููุทููุจุฉ"""
    directories = [
        EASYOCR_CONFIG["model_storage_directory"],
        DATABASE_CONFIG["backup_path"],
        OUTPUTS_DIR / "temp",
        OUTPUTS_DIR / "cache",
        LOGS_DIR / "archived",
    ]

    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

    print("โ ุชู ุฅุนุฏุงุฏ ุฌููุน ุงููุฌูุฏุงุช ุจูุฌุงุญ")


# ูุธุงุฆู ูุณุงุนุฏุฉ
def get_app_url() -> str:
    """ุงูุญุตูู ุนูู ุฑุงุจุท ุงูุชุทุจูู"""
    return f"http://{APP_CONFIG['host']}:{APP_CONFIG['port']}"


def get_model_path(model_name: str) -> Path:
    """ุงูุญุตูู ุนูู ุงููุณุงุฑ ุงููุงูู ูููููุฐุฌ"""
    return MODELS_DIR / model_name


def get_output_path(process_id: str, filename: str = "") -> Path:
    """ุงูุญุตูู ุนูู ูุณุงุฑ ุงููุฎุฑุฌุงุช ููุนูููุฉ"""
    process_dir = OUTPUTS_DIR / process_id
    if filename:
        return process_dir / filename
    return process_dir


def check_processing_config() -> bool:
    """ุงูุชุญูู ูู ุตุญุฉ ุฅุนุฏุงุฏุงุช ุงููุนุงูุฌุฉ"""
    try:
        # ุงูุชุญูู ูู ูุฌูุฏ ุงูููุงุฐุฌ ุงููุทููุจุฉ
        required_models = [
            MODEL_CONFIG["face_detection_model"],
            MODEL_CONFIG["person_detection_model"],
        ]

        print("๐ ุงูุชุญูู ูู ุฅุนุฏุงุฏุงุช ุงููุนุงูุฌุฉ...")
        print(f"๐ ูุฌูุฏ ุงูููุงุฐุฌ: {MODELS_DIR}")
        print(f"๐ฏ GPU ูุชุงุญ: {GPU_AVAILABLE}")
        print(f"โก ูุถุน ุงููุนุงูุฌุฉ: {'ุณุฑูุน' if PROCESSING_CONFIG['enable_fast_processing'] else 'ุนุงุฏู'}")

        return True

    except Exception as e:
        print(f"โ ุฎุทุฃ ูู ุงูุชุญูู ูู ุงูุฅุนุฏุงุฏุงุช: {e}")
        return False


def get_available_memory() -> Dict[str, float]:
    """ุงูุญุตูู ุนูู ูุนูููุงุช ุงูุฐุงูุฑุฉ ุงููุชุงุญุฉ"""
    memory_info = {}

    if GPU_AVAILABLE:
        memory_info["gpu_total"] = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
        memory_info["gpu_allocated"] = torch.cuda.memory_allocated() / 1024 ** 3
        memory_info["gpu_reserved"] = torch.cuda.memory_reserved() / 1024 ** 3
        memory_info["gpu_available"] = memory_info["gpu_total"] - memory_info["gpu_allocated"]

    return memory_info


def optimize_for_hardware():
    """ุชุญุณูู ุงูุฅุนุฏุงุฏุงุช ุจูุงุกู ุนูู ุงููุงุฑุฏููุฑ ุงููุชุงุญ"""
    if not GPU_AVAILABLE:
        # ุชูููู ุงูุฅุนุฏุงุฏุงุช ุนูุฏ ุงุณุชุฎุฏุงู CPU ููุท
        PROCESSING_CONFIG["batch_size"] = max(1, PROCESSING_CONFIG["batch_size"] // 2)
        PROCESSING_CONFIG["max_workers"] = 1
        PROCESSING_CONFIG["gpu_memory_limit"] = 0
        MODEL_CONFIG["precision"] = "fp32"

        print("โ๏ธ  ุชู ุชูููู ุฅุนุฏุงุฏุงุช ุงูุฃุฏุงุก ูุงุณุชุฎุฏุงู CPU ููุท")


# ุชูููุฐ ุงูุฅุนุฏุงุฏุงุช
setup_directories()
optimize_for_hardware()

# ุทุจุงุนุฉ ูุนูููุงุช ุงูุชููุฆุฉ
print("๐ฏ ุฅุนุฏุงุฏุงุช ูุธุงู ุชุญููู ุงูููุฏูู:")
print(f"๐ ุนููุงู ุงูุชุทุจูู: {get_app_url()}")
print(f"๐ ูุฌูุฏ ุงูุชุญูููุงุช: {UPLOAD_DIR}")
print(f"๐ ูุฌูุฏ ุงููุฎุฑุฌุงุช: {OUTPUTS_DIR}")
print(
    f"๐ ุฐุงูุฑุฉ GPU ุงููุชุงุญุฉ: {get_available_memory().get('gpu_available', 0):.2f} GB" if GPU_AVAILABLE else "๐ ูุง ููุฌุฏ GPU")

# ุงูุชุญูู ูู ุงูุฅุนุฏุงุฏุงุช
if not check_processing_config():
    print("โ๏ธ  ููุงู ูุดุงูู ูู ุฅุนุฏุงุฏุงุช ุงููุนุงูุฌุฉุ ูุฏ ูุคุซุฑ ุนูู ุงูุฃุฏุงุก")

print("โ ุชู ุชุญููู ุฅุนุฏุงุฏุงุช ุงูุชุทุจูู ุจูุฌุงุญ")
