# مشروع نظام تحليل الفيديو
نظام متكامل لتحليل الفيديو والصوت باستخدام الذكاء الاصطناعي. يقوم المشروع بمعالجة ملفات الفيديو لاستخراج معلومات دقيقة ومفيدة، مثل الوجوه، الأشخاص، النصوص، المشاهد، والأحداث.
## الميزات الرئيسية
**كشف وتحليل الكائنات:** يحدد ويتعقب الكائنات العامة مثل الأشخاص والوجوه بدقة.

**تحليل المشهد:** يتعرف على الأنشطة والمشاهد داخل الفيديو.

**استخراج النصوص (OCR):** يستخرج النصوص من الإطارات المرئية.

**االتعرف على الكلام:** يحول الكلام المنطوق داخل الفيديو إلى نص.

**تتبع مسارات حركة الاشخاص في الفيديو:** يتابع حركة الأشخاص عبر إطارات الفيديو المتعددة.

**واجهة برمجية (API):** يوفر واجهة API مبنية على FastAPI بالاضافة الى واجهة تفاعلية لتسهيل تحميل الفيديوهات وتشغيل عمليات التحليل وعرض النتائج.

## المتطلبات

تأكد من تثبيت المتطلبات التالية لتشغيل المشروع بشكل صحيح:

**نسخة Python:** يجب أن يكون لديك Python 3.11 أو أعلى مثبتًا.

**مكتبة FFmpeg:** مهم جداً. يجب تثبيت مكتبة FFmpeg على نظامك، حيث يستخدمها المشروع لاستخراج الصوت من الفيديوهات.

**المكتبات :** قم بتثبيت جميع المكتبات المطلوبة باستخدام الأمر التالي:

```bash
pip install -r requirements.txt
```

## التثبيت والاستخدام
### استنساخ المستودع 
```bash
git clone https://github.com/mazensomran/vedio_analysis_project.git
cd vedio_analysis_project
```
### تنزيل النماذج
يتولى المشروع عملية تنزيل النماذج اللازمة تلقائيًا عند التشغيل الأول. لذا، تأكد من وجود اتصال جيد بالإنترنت. بالنسبة للنموذج الذي ترغب باستخدامه يمكنك تحديده من ملف config.py

### تشغيل المشروع
المشروع مبني باستخدام FastAPI ويمكن تشغيله عبر Uvicorn:
```bash
uvicorn main:app --reload
```
سيقوم الأمر بتشغيل الخادم على http://127.0.0.1:8000.
### تشغيل المشروع في بيئة تطوير
بعد اكتمال التنزيل وتحميل المكتبات اللازمة قم بتشغيل المشروع في بيئة التطوير لديك من خلال تشغيل الملف main.py بعد ذلك يمكنك فتح واجهة المشروع من خلال الرابط http://127.0.0.1:8000.

### واجهة المشروع
بعد فتح الواجهة ستظهر نافذة يمكنك من خلالها تحميل الفيديو الذي ترغب بتحليله. 
بعد تحميل الفيديو يمكنك تحديد العمليات التي ترغب بإجراءها من خلال الضغط على **زر التفعيل** بجانب كل عملية, علما ان الحالة الافتراضية تكون فيها جميع العمليات مفعلة. 
بعد ذلك  اضغط على زر ب**دء التحليل**. في المرة الاولى التي تجري فيها عملية التحليل ستتأخر العملية بعض الشيئ ريثما يتم تحميل النماذج.
بعد ذلك تبدأ عملية لتحليل والتي تستغرق بضع الوقت بحسب _**طول الفيديو**_ و _**عدد العمليات**_ التي اخترت اجراءها.
بعد انتهاء عملية التحليل ستفتح صفحة النتائج في الواجهة تلقائا ويتم عرض ابرز النتائج التي تم الحصول عليها مثل:
الوجوه والعبارات النصية المكتشفة في اطارات الفيديو, النص المستخرج من الملف الصوتي للفيديو, تحليل النشاط والبيئة و مسارت الاشخاص الذين تم تتبعهم في الفيديو.
في صفحة النتائج ايضا ينمنك الولوج الى كافة الملفات الناتجة عن عملية التحليل وتصفحها, بالاضافة الى تحميل الفيديو الناتج عن عملية التحليل والذي يتضمن تتبعا لمسارات الاشخاص وتحديد الكائنات التي تظهر في الفيديو. 
بالاضافة الى ذلك ستتضمن صفحة النتائج جدولا يتضمن ملخصا لكافة النتائج التي تم الحصول عليها مع احصائيات تتعلق بعملية التحليل.
أخيرا يمكنك البدء بعملية تحليل جديدة مباشرة إما بتحديث الصفحة او بالضغط على زر "تحليل فيديو جديد" من صفحة النتائج.
## هيكل المشروع
يتكون المشروع من عدة ملفات منظمة لتسهيل عملية التطوير:
.
```
├── activity_recognizer.py # كشف وتحليل الأنشطة داخل الفيديو
├── config.py # إعدادات المشروع والمسارات
├── database.py # إدارة قاعدة البيانات (SQLite) لتخزين النتائج
├── gpu_utils.py # أدوات مساعدة لإدارة الـ GPU
├── main.py # نقطة الدخول الرئيسية للتطبيق (FastAPI)
├── model_loader.py # إدارة تحميل وتخزين نماذج الذكاء الاصطناعي
├── models.py # تعريف فئات النماذج المختلفة (كشف الوجوه، النصوص، إلخ)
├── monitoring.py # نظام مراقبة لعمليات التحليل
├── person_detector.py # كشف الأشخاص في الفيديو
├── processing_pipeline.py # مسار المعالجة الرئيسي للفيديو والصوت
├── requirements.txt # ملف متطلبات المشروع
└── README.md # ملف التوصيف هذا
```
## الترخيص
هذا المشروع مرخص بموجب ترخيص **MIT**.

## ملاحظة هامة : عند تشغيل المشروع سيتم انشاء عدد من المجلدات التي لا تظهر في هذا المستودع تتعلق بكافة البيانات المستخدمة في المشروع ابتداء من الفيديوهات المحملة للمعالجة إلى قاعدة البيانات والنماذج التي يتم تحميلها بالاضافة الى خرج عملية التحليل
